defaults:
  - base

optimizer_factory:
  group_params:
    target_params: []  # target parameters remain frozen while fine-tuning
    tuning_params:
      - lora_A.default.weight
      - lora_B.default.weight
      - lora_A.default.bias
      - lora_B.default.bias
  general_optimizer_kwargs:
    lr: ${acip.lr}
    weight_decay: 0.0
  reset_tunable_params: true  # make sure that no other parameters than above are tuned
